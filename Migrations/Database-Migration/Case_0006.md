
# ğŸ“Œ Case #6: Cassandra â†’ DynamoDB

**Real companies: Netflix (partial workloads), Airbnb (specific services), Amazon internal teams**

âš ï¸ Honesty upfront (important):
Most companies **do NOT fully replace Cassandra**.
They migrate **specific workloads** where ops pain > flexibility.

That nuance itself is interview gold.

---

## 1ï¸âƒ£ Original Setup

### Companies & Context

* **Netflix** â€“ user activity, metadata (some services)
* **Airbnb** â€“ booking & availability-related systems
* **Amazon** â€“ internal microservices at massive scale

### Initial Database

**Apache Cassandra**

### Why Cassandra Was Chosen

* Linear horizontal scalability
* High write throughput
* Multi-region replication
* No single point of failure
* Tunable consistency

### Typical Cassandra Architecture

```
App
 â†“
Cassandra Ring
(Node A â†” Node B â†” Node C â†” Node D)
```

This is **incredible engineering** â€” but comes with cost.

---

## 2ï¸âƒ£ The Breaking Point

### ğŸš¨ Why Cassandra Became Painful

#### 1. Operational Complexity

* Compaction tuning
* Repair jobs
* Node replacements
* Token rebalancing

ğŸ§  Cassandra works *until humans have to operate it*.

---

#### 2. Schema & Query Rigidity

* Data modeling must match queries
* No ad-hoc querying
* One new access pattern = new table

Example:

> â€œWe need one more queryâ€
> â†’ â€œWe need one more tableâ€

---

#### 3. Talent & On-Call Burnout

* Hard to hire deep Cassandra experts
* On-call incidents expensive
* Debugging performance issues is painful

---

#### 4. Cloud-Native Mismatch

* Cassandra â‰  managed service
* Self-managed ops in cloud is costly
* Scaling up/down is not elastic

ğŸ’¥ **Key realization**

> â€œWe donâ€™t need Cassandraâ€™s power â€” we need reliability without ops.â€

---

## 3ï¸âƒ£ Why DynamoDB?

### What DynamoDB Is

* Fully managed key-value & document store
* Automatic scaling
* Built-in HA & replication
* Pay-per-request model

### Why Not Stay on Cassandra?

| Reason     | Pain   |
| ---------- | ------ |
| Ops        | Heavy  |
| Scaling    | Manual |
| Repairs    | Risky  |
| Elasticity | Poor   |

### Why DynamoDB Won

* Zero ops
* Automatic scaling
* Strong SLA
* Tight AWS integration

ğŸ§  Netflix engineers openly said:

> â€œWe moved to managed services wherever possible to reduce operational load.â€

---

## 4ï¸âƒ£ Architecture Before vs After

### ğŸ”´ Before (Cassandra)

```
App
 â†“
Cassandra Cluster
 â†“
Manual Repairs / Scaling
```

### ğŸŸ¢ After (DynamoDB)

```
App
 â†“
DynamoDB
 â†“
Auto-scaling + Managed Replication
```

Operational complexity drops **dramatically**.

---

## 5ï¸âƒ£ Code-Level Changes (Critical Difference)

### Cassandra Table

```sql
CREATE TABLE user_activity (
  user_id TEXT,
  event_time TIMESTAMP,
  event_type TEXT,
  PRIMARY KEY (user_id, event_time)
) WITH CLUSTERING ORDER BY (event_time DESC);
```

Query:

```sql
SELECT *
FROM user_activity
WHERE user_id = '123'
LIMIT 10;
```

Works great â€” but only for this pattern.

---

### DynamoDB Table Design

```json
{
  "TableName": "UserActivity",
  "KeySchema": [
    { "AttributeName": "user_id", "KeyType": "HASH" },
    { "AttributeName": "event_time", "KeyType": "RANGE" }
  ],
  "BillingMode": "PAY_PER_REQUEST"
}
```

Query (AWS SDK â€“ Python)

```python
response = table.query(
    KeyConditionExpression=
        Key('user_id').eq('123') &
        Key('event_time').gt(1700000000),
    Limit=10
)
```

ğŸ§  Same access pattern, **no cluster management**.

---

## 6ï¸âƒ£ Migration Strategy (How Itâ€™s Actually Done)

### Production-Safe Approach

1. Identify **single-access-pattern tables**
2. Create DynamoDB tables
3. Dual write (Cassandra + DynamoDB)
4. Backfill historical data
5. Switch reads
6. Kill Cassandra tables (gradually)

âš ï¸ Cassandra often remains for:

* Analytics
* Multi-query workloads
* Cross-region custom logic

---

## 7ï¸âƒ£ Hidden Pitfalls (Very Important)

| Pitfall           | Reality                   |
| ----------------- | ------------------------- |
| Hot partitions    | Kill DynamoDB performance |
| Access patterns   | Must be fixed upfront     |
| GSIs              | Cost money                |
| Query flexibility | Very limited              |
| Vendor lock-in    | Real                      |

### Bad DynamoDB Design Example

```text
Partition key = "status"
```

ğŸš¨ One partition â†’ throttling â†’ outage.

---

## 8ï¸âƒ£ Final Outcome

### What Improved

âœ” Zero ops
âœ” Auto scaling
âœ” Predictable performance
âœ” Reduced on-call load

### What Got Worse

âœ˜ Query flexibility
âœ˜ Vendor lock-in
âœ˜ Cost spikes if misused

### When NOT to Migrate

* Complex querying
* Analytics-heavy workloads
* Multi-access-pattern tables

---

## ğŸ¯ Interview Preparation Section

### Interview Question

> â€œWhy move from Cassandra to DynamoDB?â€

**Strong Answer**

> â€œTo reduce operational complexity and leverage managed scalability for predictable access-pattern workloads.â€

### Follow-up Points

* Hot partitions
* GSIs
* Cost model
* Dual writes

---

## ğŸ‘¨â€ğŸ’» Production Engineer Lessons

* Ops cost is real engineering cost
* Managed services trade flexibility for reliability
* Cassandra is powerful, but unforgiving
* Design access patterns first, schema later

---
