
# üìå Case #1: MongoDB ‚Üí PostgreSQL (Real SaaS Platforms)

Real engineering teams and startups have migrated successfully from MongoDB to PostgreSQL as they scaled.

---

## 1Ô∏è‚É£ Original Setup

**Company (Representative Example): Voucherify**
Voucherify started as a SaaS platform for promotional campaigns, initially using **MongoDB** as the primary database. 

**Why MongoDB Initially?**

* Schema-less development allowed *rapid prototyping*
* JSON storage matched existing entity shapes
* Low operational overhead for the first million users
  This is a *typical startup pattern*: schema agnostic + fast iteration. 

**At Early Scale:**

* 3+ database clusters across continents
* Millions of records
* Mixed data models (users, codes, redemption history)

---

## 2Ô∏è‚É£ The Breaking Point

### üö© Pain Points With MongoDB

By the time Voucherify hit serious scale, several issues had emerged:

1. **Transactional Complexity**

   * Hard to guarantee consistent ACID behavior across multi-step operations without custom code
2. **Performance & Cost**

   * Queries, especially analytics and joins performed poorly compared to relational systems
   * Operational costs climbing with shards and replica sets
3. **Tooling & Analytics**

   * Harder integration with BI tools

These are classic growth pain indicators that suggest **MongoDB isn‚Äôt the right long-term operational database when relational constraints matter**. 

---

## 3Ô∏è‚É£ Why PostgreSQL?

**Decision Drivers**

| Requirement                        | Favor                  |
| ---------------------------------- | ---------------------- |
| ACID transactions                  | PostgreSQL             |
| Complex joins                      | PostgreSQL             |
| Mature ecosystem                   | PostgreSQL             |
| Lower operational cost             | PostgreSQL             |
| JSON but with relational integrity | PostgreSQL (via JSONB) |

**Alternatives Considered**

* Stay on MongoDB with added operational cost
* Hybrid NoSQL + SQL (but complexity increases)
* Other SQL (MySQL) ‚Äî didn‚Äôt offer as strong JSON support

**Why PostgreSQL Won**

* Mature, strongly typed transactional system
* JSONB to support semi-structured data
* Easier analytics integration

*Note:* Similar real companies ‚Äî **The Guardian** also migrated from MongoDB to PostgreSQL as they matured their backend.

---

## 4Ô∏è‚É£ Architecture Before vs After

### üîπ Before: MongoDB-centric

```
Clients ‚Üí App Servers ‚Üí MongoDB
                ‚Üì
                Analytics / Reporting (external ETL)
```

* App layer handles joins, transactions manually
* Multiple Mongo clusters regionally

### üî∑ After: PostgreSQL-centric

```
Clients ‚Üí App Servers ‚Üí PostgreSQL
            ‚Üò          |
             ‚Üí API    ‚Üí BI / Reporting (Direct SQL)
```

* PostgreSQL serves as *single source of truth*
* JSONB allows storing semi-structured parts
* Transactional integrity at DB level

---

## 5Ô∏è‚É£ Code-Level Changes

### 1. Schema Modeling

**Mongo Schema (Node.js with Mongoose)**

```js
// Offers.js
const offerSchema = new mongoose.Schema({
  code          : String,
  discount      : Object,
  conditions    : Object,
  createdAt     : Date
});
```

**PostgreSQL Schema (SQL)**

```sql
CREATE TABLE offers (
  id          SERIAL PRIMARY KEY,
  code        TEXT NOT NULL UNIQUE,
  discount    JSONB NOT NULL,
  conditions  JSONB NOT NULL,
  created_at  TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

üëâ JSON ‚Üí JSONB gives similar flexibility *but with indexing & constraints*.

---

### 2. Data Migration Script (Node.js)

**Extract from Mongo & Insert into Postgres**

```js
const { Client } = require('pg');
const mongo = require('mongodb').MongoClient;

async function migrate() {
  const pg = new Client();
  await pg.connect();

  const client = await mongo.connect(process.env.MONGO_URL);
  const db = client.db('voucherify');

  const cursor = db.collection('offers').find();
  while (await cursor.hasNext()) {
    const doc = await cursor.next();
    await pg.query(
      `INSERT INTO offers(code, discount, conditions, created_at)
       VALUES ($1, $2, $3, $4)`,
      [doc.code, doc.discount, doc.conditions, doc.createdAt]
    );
  }

  await pg.end();
  await client.close();
}
migrate();
```

**Interview-ready Note:**
This simple loop may be fine for *small migrations* but real production systems use:

* *Batching*
* *Streaming*
* *Parallel workers*

to avoid memory spikes.

---

## 6Ô∏è‚É£ Migration Strategy

### üß† Dual Writes (Optional Phase)

Systems with minimal downtime implement:

1. App writes to both MongoDB and PostgreSQL
2. Once PostgreSQL is fully warmed up, reads switch gradually
3. Eventually, MongoDB is decommissioned

This dual-write approach avoids downtime while keeping data consistent ‚Äî exactly what many scalable SaaS migrations do in practice.

### üóÇ Data Backfill

* Export all historical data via scripts
* Validate row counts
* Validate referential integrity

### üß™ Testing

* SQL queries vs expected output
* Performance benchmarks

---

## 7Ô∏è‚É£ Hidden Pitfalls (Be Brutally Honest)

| Challenge     | Impact                                                         |
| ------------- | -------------------------------------------------------------- |
| Schema Design | Mongo‚Äôs schema-less ‚Üí may bloat relational schema              |
| Index tuning  | Must rethink indexes for SQL semantics                         |
| Legacy code   | Many application queries must be rewritten                     |
| JOINS         | Previously in app logic ‚Üí now in DB                            |
| Transactions  | PostgreSQL enforces ACID; you *must handle rollbacks properly* |

üëâ **Lesson:** Migration is *not* just data transfer ‚Äî it‚Äôs a redesign of how data is accessed, validated, and maintained.

---

## 8Ô∏è‚É£ Final Outcome

**What Improved**
‚úî ACID guarantees
‚úî Complex query performance
‚úî Lower operational cost
‚úî Analytics integration simplified

**What Still Sucks**
‚úò Migration effort is high
‚úò Teams must learn SQL depths
‚úò ORM changes and refactors required

**When NOT to Copy This**
If your data access is *simple CRUD with no joins* and you have no transactional requirements ‚Äî MongoDB might still be fine.

---

## üß† Interview + Production Lessons

### ‚ùì Interview Talking Points

‚úî Explain dual-write vs big-bang migrations
‚úî Why relational integrity matters at scale
‚úî JSONB as a compromise between NoSQL flexibility & SQL power
‚úî The cost vs operational tension

### üë®‚Äçüíª Production Takeaways

‚úî Design for rollback before migrating
‚úî Use schema migrations (Flyway / Liquibase)
‚úî Benchmark before and after

---

## üìå Summary

**Case:** SaaS platform migrating **MongoDB ‚Üí PostgreSQL**
**Why:** Transaction integrity, performance, analytics, cost
**Real world:** Voucherify and other startups have done this in production systems ‚Äî sometimes with dual writes to avoid downtime.

---